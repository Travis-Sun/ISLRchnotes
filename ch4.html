<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>统计学习导论-分类</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>



<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</head>

<body>
<h1>统计学习导论-分类</h1>

<h1>logistic回归</h1>

<ul>
<li>因变量以概率形式出现</li>
<li>\( p(X) = \frac {e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}} \)</li>
<li>变形后\( \frac {p(X)}{1 - p(X)} \) 为胜率，比概率应用更实际些，去对数后为对数胜率（logit）</li>
<li>因变量\( p(X) \)与自变量间关系非线性</li>
<li>用极大似然估计确定参数，似然函数为\( l(\beta_0, \beta_1) = \prod_{i:y_i = 1} p(x_i) \prod_{i':y_i^' = 0} (1 - p(x_{i'})) \)，该函数取最大值</li>
<li>线性回归中，最小二乘法为极大似然估计的特例</li>
<li>混杂因素的解释上要考虑单因素回归与多元回归</li>
<li>多响应logistic回归一般被判别分析取代</li>
</ul>

<h1>线性判别分析</h1>

<ul>
<li>使用原因：分类离散时logistic回归不稳定，n小X正态时更稳定，适用于多响应</li>
<li>贝页斯理论：\( Pr(Y = k|X = x) = \frac{\pi_k f_k(x)}{\sum_{l = 1}^K \pi_lf_l(x)} \) 其中\( \pi \) 代表先验概率，估计\( f_k(X) \)需要对\( x \)的分布作出假设</li>
<li>自变量为1时，假定\( f_k(x) \)分布为正态的，有\( f_k(x) = \frac{1}{\sqrt{2 \pi} \sigma_k} exp(- \frac{1}{2 \sigma_k^2} (x - \mu_k)^2) \)，代入可得\( p_k(x) \)，取对数有\( \sigma_k(x) = x \cdot \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} + log(\pi_k) \)，使\( \sigma_k(x) \)最大的分类方法为判定边界</li>
<li>贝页斯分类器需要知道所有分布参数，实际中会采用线性判别分析（LDA），通过以下训练集估计方法来插入贝页斯分类器：\( \hat \pi_k = n_k/n \)、\( \hat \mu_k = \frac{1}{n_k} \sum_{i:y_i = k} x_i \) 与 \( \hat \sigma^2 = \frac{1}{n - K} \sum_{k = 1}^K \sum_{i:y_i = k} (x_i - \hat \mu_k)^2 \)</li>
<li>线性体现在判别函数\( \hat \sigma_k(x) \)的形式是线性的</li>
<li>自变量多于1时，假设自变量均来自多元正态分布的分类</li>
<li>列连表，表示假阳性，假阴性，可计算灵敏度与特异性</li>
<li>LDA是对贝页斯分类的模拟，旨在降低总错误率，因此灵敏度与特异性区分并不明显，可根据实际需要调节</li>
<li>ROC曲线用来展示两种错误，横坐标假阳性，纵坐标真阳性</li>
</ul>

<h1>二次判别分析（QDA）及其它</h1>

<ul>
<li>不同于LDA，二次判别分析考虑各分类参数中方差不同而不是相同，引入了二次项</li>
<li>对分类描述更为精细，但容易过拟合，样本较少，LDA优先</li>
<li>对比logistic回归，两者数学形式相近，取值上logistic回归使用极大似然法，LDA使用共方差的高斯分布假设，结论多数条件一致，但随假设不同而不同</li>
<li>KNN更适用于非线性关系，标准化很有必要，QDA相对温和</li>
</ul>

</body>

</html>

